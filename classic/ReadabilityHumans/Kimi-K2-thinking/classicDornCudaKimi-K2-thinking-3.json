{"score":"45","reasoning":"Critical typo d_jont_hist reduces clarity. Commented code lacks context. Uses outdated CUDA_SAFE_CALL macro without modern error handling. No comments explaining kernel parameters or purpose. Missing kernel launch error check. Minimal variable naming is acceptable but overall poor maintenance and documentation hinder comprehension despite simple structure.","tokens":1257,"name":"103.jsnp"}
{"score":"68","reasoning":"Code shows consistent structure for CUDA kernel launches with error checking. However readability suffers from inconsistent error messages, unexplained magic numbers like 16 in iAlignUp, unclear shared memory calculation particlesNumber+2, long unaligned parameter lists, and repetitive texture binding code. Missing closing brace and limited comments reduce comprehension. Function names are descriptive but implementation details lack clarity.","tokens":1998,"name":"47.jsnp"}
{"score":"55","reasoning":"Code exhibits poor readability due to dense multi-condition checks including non-obvious NaN tests, magic numbers requiring explanatory comments, and complex texture memory indexing. High domain specificity for image registration with repetitive derivative patterns for X Y Z axes adds comprehension burden. Variable names are descriptive but overshadowed by intricate logic and implicit knowledge requirements.","tokens":1972,"name":"81.jsnp"}
{"score":"50","reasoning":"Code intent is clear but readability suffers from unused variables (idnx, bx, by), type mismatch (double vs cudafloat), missing bounds checking, and incomplete host function lacking kernel launch. Hardcoded values and inefficient 2D grid usage add confusion. No inline comments. These issues make comprehension difficult and raise safety concerns.","tokens":1898,"name":"106.jsnp"}
{"score":"75","reasoning":"Code demonstrates good structure with clear function-level comments and a helpful reference link. Variable names are mostly descriptive and logic follows standard ray tracing patterns. However mathematical density requires domain knowledge, some variable names are terse like r M v, and the snippet starts with an incomplete line. Overall well-commented for experienced graphics programmers but less accessible to novices.","tokens":2000,"name":"90.jsnp"}
{"score":"58","reasoning":"Code shows inconsistent formatting with mixed tabs and spaces. Constructor lacks clear signature. Destructor has unsafe memory freeing patterns mixing free and pFreeHost without null checks for all pointers. Uses C-style memory management in C++. Variable names are somewhat descriptive but inconsistent. Minimal comments. Overall structure is understandable but contains potential bugs and outdated practices that hinder readability.","tokens":2005,"name":"73.jsnp"}
{"score":"30","reasoning":"Code suffers from cryptic naming conventions (Tx_x, xFirst, tempBasis) that lack semantic clarity. Highly repetitive pattern without abstraction makes it hard to discern overall algorithm. No comments explain the mathematical operations. Interleaved calculations for displacement and derivatives reduce comprehension. Requires significant domain knowledge to understand purpose. Dense structure obscures intent despite predictable pattern.","tokens":1976,"name":"50.jsnp"}
{"score":"45","reasoning":"Overly verbose variable names hinder readability. No comments explain texture binding, memory clearing, or grid dimension calculations. CUDA_SAFE_CALL macro obscures error handling. Double pointer dereferencing adds complexity without justification. Magic number 0 in cudaBindTexture is unclear. Dense code structure lacks visual separation, making it hard to follow the setup sequence for kernel launch.","tokens":1877,"name":"67.jsnp"}
{"score":"72","reasoning":"Incomplete Python list missing opening bracket. Strings are clear directory names with consistent formatting. Simple structure but lacks context for full understanding. Readable elements but incomplete code fragment requires inference.","tokens":808,"name":"96.jsnp"}
{"score":"38","reasoning":"Extremely long variable names make lines hard to read. Functions have excessive parameters reducing clarity. Array indexing uses confusing patterns. Mixed naming conventions with no comments. Inconsistent indentation. Backslashes suggest macro context adding complexity. Linear structure is present but significant issues hinder comprehension.","tokens":2413,"name":"93.jsnp"}
{"score":"55","reasoning":"Missing stdlib.h for malloc, memory leaks for devPtr and backPtr, commented code creates confusion, inconsistent formatting, unused includes, unexplained magic number 126, and incomplete error checking. Single-line for loop without braces reduces clarity. Basic structure is logical but multiple issues hinder readability and indicate poor maintenance.","tokens":2178,"name":"31.jsnp"}
{"score":"90","reasoning":"The code demonstrates excellent readability through descriptive naming conventions and a clear linear structure. Function names like SingleScalarVolumePrepare and IsosurfaceRayCasterPrepare clearly indicate their purpose. The error handling pattern with early returns is straightforward. However, single-line if statements without braces and absence of comments slightly reduce readability. The function is concise and easy to comprehend for its domain, showing good software engineering practices.","tokens":1941,"name":"57.jsnp"}
{"score":"52","reasoning":"Poor formatting with no spaces after commas makes parameters hard to parse. Inconsistent naming conventions mix PascalCase, snake_case and Hungarian notation. No comments or documentation for parameters reduces comprehension. While thread index calculations are standard CUDA patterns, the overall density and inconsistency hinder readability.","tokens":1986,"name":"58.jsnp"}
{"score":"55","reasoning":"CUDA parallel reduction with readability issues. No comments, magic numbers, dense format, chained assignment. Recognizable pattern for experts but cryptic for others. Systematic progression provides some clarity. Lacks self-documentation needed for research code.","tokens":2216,"name":"21.jsnp"}
{"score":"45","reasoning":"Code snippet lacks function signature and context. Variable names are cryptic or excessively long. Minimal comments fail to explain magic numbers like binning*(binning+2) or hardcoded array indices. Inconsistent indentation and reliance on undefined global variables reduce clarity. Repetitive CUDA calls are verbose. Only positive aspects are const correctness and basic CUDA structure. Requires domain expertise to comprehend.","tokens":2480,"name":"89.jsnp"}
{"score":"35","reasoning":"Code snippet lacks context starting with closing braces. Severe duplication in switch statement violates DRY principle. No default case for error handling. Magic numbers without explanation. Inconsistent formatting and spacing. No comments explaining purpose or parameters. Suspicious logic assigning count to RMS value. Understandable for CUDA developers but maintenance is difficult due to repetitive pattern and missing documentation.","tokens":2611,"name":"36.jsnp"}
{"score":"10","reasoning":"Fragment starts mid-statement with 16 numbered variables b0-b15. Uses cryptic single-letter names a-e and functions with 30+ parameters. Heavy macro usage including token pasting (##length##) obscures logic. No comments inconsistent formatting and backslash continuations show this is preprocessor code optimized for performance not readability. Requires extensive external context to comprehend.","tokens":2344,"name":"98.jsnp"}
{"score":"38","reasoning":"Poor indentation obscures control flow. Cryptic names (po, n_bin, echan) lack meaning. Dense code without spacing. Magic numbers unexplained. Commented-out code creates clutter. Static variables add hidden state complexity. Nested loops are misaligned. Overall difficult to parse and understand quickly.","tokens":2674,"name":"112.jsnp"}
{"score":"68","reasoning":"Code shows moderate readability with descriptive variable names and helpful comments. However, inconsistent naming conventions, redundant logic in min/max calculations, long parameter lists, and magic constants reduce clarity. The commented-out maxSteps calculation is confusing. Overall structure is understandable but needs cleanup for better maintainability.","tokens":1983,"name":"28.jsnp"}
{"score":"50","reasoning":"Snippet is incomplete hindering full understanding. Inconsistent naming between host kernel variables like idnx idny tx ty bx by wC hC uiWC uiHC BLOCK_SIZE blockSize. Poor indentation. Undefined identifiers cudafloat tx ty bx by Csub BLOCK_SIZE. Minimal comments. No CUDA error checking. These factors severely reduce readability.","tokens":2800,"name":"101.jsnp"}
{"score":"50","reasoning":"Severe indentation inconsistencies make control flow difficult to follow. Commented-out code clutters the logic. NULL pointer check occurs after usage showing logical errors. While high-level comments explain the FFT convolution workflow and error macros are used, inconsistent spacing, cryptic names, and deprecated API calls reduce readability significantly.","tokens":3299,"name":"20.jsnp"}
{"score":"60","reasoning":"The code snippet lacks context as it starts and ends abruptly within functions. Undefined variables like inArgs and outArgs reduce comprehension. However the detailed comment explains the threading model and design rationale well. Function structure is clear with reasonable variable names and error handling. The incomplete nature significantly impacts readability despite good commenting.","tokens":1804,"name":"60.jsnp"}
{"score":"55","reasoning":"Inconsistent indentation and spacing reduce clarity. Variable names like sourceImageArray_d and sourceRealToVoxel_h are cryptic despite CUDA conventions. Multiple statements per line and magic numbers like 3*sizeof(float4) hinder readability. Minimal comments with duplicates. Logic is understandable for experienced developers but lacks error checking for pointers and is not modular. Overall structure is logical but execution is poor.","tokens":1816,"name":"23.jsnp"}
{"score":"72","reasoning":"Code demonstrates clear singleton pattern with lazy initialization. Naming is mostly descriptive but Fill method is ambiguous. Major readability issues include missing error handling for cuRAND calls, no thread safety mechanisms for static members, and lack of class definition context. atexit usage is non-idiomatic and may confuse readers. Overall structure is logical but lacks production-ready clarity.","tokens":1469,"name":"116.jsnp"}
{"score":"40","reasoning":"Code suffers from cryptic variable names (tid, posID, f, cr, jr, L) requiring domain knowledge. Exponential crossover uses nested ternaries that are extremely hard to parse. Minimal comments explain what but not why. CUDA primitives are used directly without abstraction. Logic is overly dense in single lines. While structurally sound, comprehension requires deep familiarity with Differential Evolution algorithms and CUDA patterns.","tokens":1877,"name":"46.jsnp"}
{"score":"72","reasoning":"Clear variable names and logical structure with a helpful comment. Main readability issue is the dense fprintf line lacking spacing and line breaks. Mixed indentation and minor style inconsistencies. The break condition is understandable. Overall functional but needs formatting cleanup for better comprehension.","tokens":1355,"name":"65.jsnp"}
{"score":"48","reasoning":"Heavy macro usage (CUDA_VALUE, CUDA_SIGMOID, NEURON) obscures logic. Complex indexing arithmetic requires domain knowledge. Template reduction functions lack definition context. Cryptic variable names (iw, i_w, M, outn) and magic number 32 reduce clarity. Mixed forward pass and gradient computation adds cognitive load. Structure follows recognizable CUDA patterns but overall comprehension requires significant external context and expertise.","tokens":3405,"name":"61.jsnp"}
{"score":"25","reasoning":"Variable names are overly cryptic with unclear abbreviations like mapQ maxdiff sa mm fnr and mysterious _de suffix. Lacks context no function name or comments. Inconsistent naming patterns. Only n_seqs n_block are somewhat clear. Requires domain expertise. Clean formatting cannot compensate for poor naming.","tokens":1722,"name":"35.jsnp"}
{"score":"65","reasoning":"Network functions with clear naming but inconsistent formatting. Irregular spacing, missing comments, and magic numbers hurt readability. Incomplete snippet limits context. Error handling is consistent but abrupt. Pointer arithmetic is correct but dense. Decent structure for socket programming but style issues reduce comprehension.","tokens":1751,"name":"102.jsnp"}
{"score":"50","reasoning":"Code suffers from inconsistent formatting, commented-out code blocks, and missing error checking for cudaMemcpy calls. Memory leaks for devPtr and backPtr reduce clarity. Redundant casts and inconsistent error message style hinder readability. While the basic memory transfer logic is understandable, these issues significantly impact overall comprehension.","tokens":2253,"name":"39.jsnp"}
{"score":"58","reasoning":"Code shows clear intent with separable 2D convolution structure and helpful comments. However, inconsistent naming conventions, unused status variable, non-standard indentation, unclear memory management with missing buffer deallocation, unexplained magic number 2 in kernel offset calculation, and lack of input validation hinder readability. Function dependencies are opaque. Overall structure is logical but style issues impede comprehension.","tokens":2295,"name":"68.jsnp"}
{"score":"65","reasoning":"CUDA reduction fragment finding minimum value and position. Repetitive manual unrolling for varied block sizes requires CUDA expertise to grasp warp-synchronous volatile pointer optimization. Verbose structure needs loops or templates. Lacks comments on volatile usage. Clear variable names but repetitive pattern and missing context hinder comprehension. Accessible to CUDA developers but cryptic to others.","tokens":2787,"name":"99.jsnp"}
{"score":"32","reasoning":"Cryptic variable names like lg, lgn, i, n make intent unclear. Dense indexing calculations lack explanation. Complex bit manipulation for reduction is hard to follow without comments. Inconsistent formatting and magic numbers like +1 in connection calculation reduce clarity. Frequent syncthreads without clear thread collaboration pattern. Code appears incomplete. Requires significant domain knowledge to understand.","tokens":2006,"name":"18.jsnp"}
{"score":"50","reasoning":"Code shows poor readability with cryptic variable names like posID setID, macro IMUL without definition, includes .cu file unusually, uses preprocessor directives for dual logic paths, has magic numbers, incomplete ending brace, unused g_globalBestID parameter, and questionable __syncthreads placement. Lacks modern C++ practices and type safety with generic shared memory array.","tokens":2090,"name":"42.jsnp"}
{"score":"58","reasoning":"Function signature with 11 parameters is overly complex. Long descriptive names are good but become verbose. Heavy CUDA boilerplate obscures logic. Relies on external constants and symbols. Inconsistent indentation reduces clarity. Debug block adds clutter. While patterns are consistent and naming is descriptive, the density of GPU-specific code and parameter complexity make moderate comprehension effort required.","tokens":2600,"name":"64.jsnp"}
{"score":"88","reasoning":"Simple clear structure with descriptive variable names. Print statements use consistent formatting. Comments explain subsequent operations. Minor deductions for hardcoded tab alignment. Overall very easy to follow for a C code snippet.","tokens":1374,"name":"107.jsnp"}
{"score":"15","reasoning":"Extremely poor readability due to 20+ parameter function calls with cryptic variable names b0-b15 p0-p15. Macro token pasting syntax adds complexity. No comments or meaningful abstraction. Code mixes hashing hash checking counting and counter incrementing violating single responsibility. High cognitive load required to understand purpose making maintenance very difficult.","tokens":1669,"name":"92.jsnp"}
{"score":"30","reasoning":"Code fragment shows poor readability with empty if block anti-pattern requiring mental inversion. Function call has excessive 19 parameters with cryptic b0-b15 naming offering no semantic meaning. Complex condition lacks clarity and comments. Structure suggests GPU programming without proper abstraction layers. Overall comprehension severely hindered by parameter count and inverted logic pattern.","tokens":1660,"name":"55.jsnp"}
{"score":"60","reasoning":"Mixed tabs and spaces create inconsistent indentation hurting readability. Commented-out code line adds clutter. Variable names are mostly descriptive like g_attenuation but s_sino is cryptic. Operations are clear: attenuation sum and exponential backprojection. CUDA context is evident from threadIdx.x. Overall structure is understandable but formatting issues significantly impact comprehension.","tokens":1962,"name":"12.jsnp"}
{"score":"40","reasoning":"Code snippet shows CUDA kernel launch with poor readability. Variable names like G1 B1 are cryptic. Commented-out allocation code creates confusion without explanation. Requires deep CUDA knowledge to understand triple bracket syntax and d_ prefix convention. Missing context about function purpose. No comments explaining kernel logic or synchronization need. While structurally simple the code is not self-explanatory and mixes active code with unexplained commented sections.","tokens":1194,"name":"72.jsnp"}
{"score":"20","reasoning":"Macro definitions are confusing and counter-intuitive, swapping row and column indices. Using function-like macros for array declarations creates invalid syntax and obscures intent. Cryptic naming conventions and commented-out alternatives suggest developer confusion. The code is poorly readable and difficult to maintain.","tokens":1631,"name":"11.jsnp"}
{"score":"35","reasoning":"Heavy macro usage with commented alternatives creates confusion about memory layout. Undefined HMATRIX macro hinders understanding. Complex nested loops with multiple boundary conditions and magic numbers reduce clarity. Unconventional macro-based shared memory declaration is obscure. No comments explain algorithm intent. Dual-element loading pattern per thread is not immediately obvious. Overall structure is difficult to follow without extensive domain knowledge.","tokens":3212,"name":"7.jsnp"}
{"score":"40","reasoning":"The code uses poor variable names like p i j matrix query without descriptive context. Complex nested array indexing reduces clarity. The comment is trivial. CUDA API calls require specialized knowledge and have dense parameters. While vertical alignment shows a pattern, overall comprehension demands significant domain expertise and missing contextual understanding.","tokens":1623,"name":"85.jsnp"}
{"score":"50","reasoning":"Simple macro is readable but includes are disorganized. Mixes CUDA headers with custom header using non-standard naming. Contains commented-out code without explanation. Lacks header guards, grouping, or comments. Poor structure suggests minimal maintenance, reducing overall comprehension.","tokens":1428,"name":"88.jsnp"}
{"score":"55","reasoning":"Code suffers from unclear macro usage IMUL BETTER_THAN MAXIMIZE undefined here, heavy reliance on preprocessor splits core logic. Variable naming is confusing, solutionNumber is unused, and relationship between solutionID actualSolutionSize problemDimension is opaque. Magic numbers 0.1f 0.2f lack context. Complex 2D grid flattening. While structurally sound for CUDA, these issues hinder quick comprehension.","tokens":3228,"name":"0.jsnp"}
{"score":"70","reasoning":"Descriptive variable names with g_ s_ prefixes aid clarity but formatting is inconsistent with mixed tabs and spaces. Minimal comments for complex medical imaging algorithm. Shared memory usage pattern is unclear. External dependencies like BLOCK are undefined. Indexing logic requires careful study. Commented debug line is distracting. Overall structure is logical but needs better documentation and consistent formatting.","tokens":2044,"name":"104.jsnp"}
{"score":"40","reasoning":"Code suffers from poor readability due to unused macros and includes, inconsistent naming conventions, abbreviated variable names, magic numbers like 12*sizeof(float), manual element-by-element matrix copying, lack of error checking for calloc, and unclear function purpose. Comments are minimal and don\u0027t explain intent. Overall structure is functional but maintenance would be difficult.","tokens":3560,"name":"100.jsnp"}
{"score":"35","reasoning":"Code suffers from multiple undefined symbols (IMUL, BETTER_THAN, s_addends, t_texFitnesses), incomplete logic (never writes to g_localBestIDs), inconsistent types, and confusing indexing for ring topology. Commented-out __syncthreads() suggests synchronization issues. Doxygen comments help but cannot compensate for missing context and implementation gaps.","tokens":2473,"name":"26.jsnp"}
{"score":"48","reasoning":"Extremely long parameter lists reduce readability. Cryptic variable names J and I lack context. Preprocessor directives interrupt logical flow. Second kernel is incomplete. No comments or documentation. Requires deep RBM domain knowledge. While code structure is logical, these issues significantly hinder comprehension for new developers or maintainers.","tokens":2307,"name":"3.jsnp"}
{"score":"35","reasoning":"Code suffers from complex bit manipulation without abstraction, use of goto harming flow clarity, magic numbers, and insufficient context. Comments are sometimes unhelpful or justify poor practices. Variable names are somewhat descriptive but overall logic is hard to follow due to dense conditions and missing surrounding structure.","tokens":1782,"name":"19.jsnp"}
{"score":"55","reasoning":"Code shows good structure with clear comments and descriptive variable names. The ray-box intersection algorithm is standard and well-explained. However, the snippet is incomplete missing return logic and assignments to tnear/tfar. There is a probable bug using tmin.x and tmax.x twice instead of tmin.y/tmax.y which severely impacts comprehension. Unused declarations add minor confusion.","tokens":2098,"name":"13.jsnp"}
{"score":"55","reasoning":"CUDA reduction pattern with templated block sizes but poor readability. Heavy code duplication in switch statement, hardcoded warp size 32, no comments, and missing context for helper functions create high cognitive load. Archaic FERMI directive and unclear variable scoping hinder understanding. Requires substantial CUDA knowledge despite following some conventions.","tokens":2470,"name":"51.jsnp"}
{"score":"72","reasoning":"Functions are short with clear descriptive names and consistent structure. Block and inline comments effectively explain purpose and error handling. However, missing #include \u003cstdlib.h\u003e for exit() reduces completeness. Parameters should be const char* for clarity. Code duplication between functions could be refactored, but doesn\u0027t severely impact readability. Overall, easy to understand with minor technical issues.","tokens":2027,"name":"41.jsnp"}
{"score":"65","reasoning":"Code shows moderate readability with logical CUDA kernel structure and helpful comments for pixel indexing. However, inconsistent naming conventions mix camelCase, snake_case and Hungarian notation. Variable names are sometimes cryptic (r, v, M) and lack context. The snippet ends abruptly without showing full logic. Missing documentation for the kernel\u0027s purpose and parameters reduces comprehension. Overall structure is sound but needs naming consistency and better documentation.","tokens":2389,"name":"14.jsnp"}
{"score":"20","reasoning":"Code uses macro-generated CUDA kernels with extremely long parameter lists containing 48+ cryptically named variables. Heavy reliance on line continuations and single-letter identifiers makes data flow nearly impossible to trace. While the pattern is consistent, the lack of comments, semantic naming, and separation of concerns results in very poor readability typical of performance-optimized GPU code.","tokens":1747,"name":"16.jsnp"}
{"score":"40","reasoning":"Code snippet lacks context and uses cryptic variable names t tstep pos step without comments. The __syncthreads call purpose is unclear without surrounding code. While structure is clean and operations are simple the overall comprehension is poor due to missing information and non descriptive identifiers.","tokens":1954,"name":"62.jsnp"}
{"score":"75","reasoning":"Function name is clear and d_ prefix convention is good. However unused BLOCK macro creates major confusion. Parameter naming is redundant. Single-line implementation is dense. Lacks error checking and comments. Simple structure but these issues impact readability.","tokens":1789,"name":"105.jsnp"}
{"score":"35","reasoning":"Poor variable naming h_o h_h ppc m i lacks clarity. No comments on first function. Second function has minimal comment but contains likely indexing bug in h_h calculation causing overlap. Magic number 2 used without constant. Loop condition i \u003c\u003d ppc/2 is ambiguous about middle point inclusion. Missing error handling for NULL pointers or division by zero. Simple nested loop structure is only redeeming quality but overall comprehension is severely hindered by cryptic names and potential bugs.","tokens":1850,"name":"119.jsnp"}
{"score":"35","reasoning":"Extremely long function signature with 11 parameters including multiple double pointers makes comprehension difficult. Inconsistent naming (rmsF vs bestRMS, r vs lastDeltaWithoutLearningMomentum) reduces clarity. No comments explain purpose or parameters. Shared memory initialization suggests potential race condition. Incomplete snippet and use of KERNEL macro instead of explicit CUDA syntax further obscure understanding.","tokens":1872,"name":"6.jsnp"}
{"score":"70","reasoning":"CUDA kernel for z-axis convolution lacks explanatory comments. Index arithmetic with radius offset is dense and not transparent. short type for z is inconsistent. Condition -1\u003cz is unconventional. Requires domain knowledge and careful study to understand windowing logic.","tokens":2079,"name":"9.jsnp"}
{"score":"48","reasoning":"Code suffers from inconsistent formatting, cryptic variable names like t_m_a_h, and magic numbers without context. Comments have typos and lack depth. Multiple statements per line and inconsistent indentation hinder readability. The grid dimension logic contains unclear constants and potential bugs. While functional, the code requires significant effort to understand and maintain.","tokens":2624,"name":"115.jsnp"}
{"score":"65","reasoning":"Cryptic but consistent variable naming p101 w000 for trilinear interpolation corners and weights. No comments but pattern is mathematically clear. Repetitive calculations could be loops but may be intentional unrolling for CUDA performance. Complex 3D indexing is verbose. Logical structure aids comprehension for domain experts but hinders general readability.","tokens":3242,"name":"82.jsnp"}
{"score":"35","reasoning":"Code suffers from heavy macro usage obscuring CUDA primitives, undefined constants like NUM_NEURONS NEURON OUTPUT_NEURON, cryptic naming like rmsF lg, complex pointer arithmetic, and potential synchronization bugs from early return. Ten parameters with several unused add clutter. No comments explain shared memory layout or algorithm. Only comprehensible to those deeply familiar with the codebase.","tokens":2220,"name":"87.jsnp"}
{"score":"65","reasoning":"Standard CUDA kernel with clear parameters but cryptic idnxidny variable names. Inconsistent use of bxby versus blockIdx reduces clarity. External macros KERNELcudafloat require context. Readable for CUDA experts but not self-explanatory. Needs better naming and consistency for broader comprehension.","tokens":2912,"name":"111.jsnp"}
{"score":"30","reasoning":"Macro heavy design with cryptic variable names like b0 through b15 and p0 through p15 plus excessive parameter lists makes comprehension difficult. Function name and incrementCounters call use token pasting suggesting code generation. CUDA specifics add complexity. While loop structure is clear the body mixes abstraction levels poorly. Requires deep MD4 and CUDA knowledge to understand.","tokens":2924,"name":"24.jsnp"}
{"score":"35","reasoning":"The code is dense with vector components .w .x .y .z making it cryptic. Repetitive blocks lack abstraction. Comments explain lines but not the overall algorithm. Requires deep CUDA and domain knowledge. Inconsistent spacing. Clearly performance-optimized at the expense of readability.","tokens":2454,"name":"113.jsnp"}
{"score":"72","reasoning":"Mixed naming conventions like Hungarian notation iRetVal versus camelCase startDevice and domain-specific abbreviations htod dtoh dtod wc reduce clarity. Inconsistent spacing around parentheses and uninitialized variable modeStr are concerns. Excessive section separators. Simple structure and clear ternary exit status help but style inconsistencies hinder overall readability.","tokens":3595,"name":"5.jsnp"}
{"score":"40","reasoning":"The code suffers from major readability issues. The macro invocations lack definitions making their purpose opaque. The comment is misleading as it mentions copying to host but the function copies to device constant memory. The threadId parameter is unused. A magic number 8192 appears without explanation. The size calculation is unclear and may be erroneous. Heavy reliance on external symbols and macros requires extensive context to understand.","tokens":1537,"name":"43.jsnp"}
{"score":"70","reasoning":"The code shows moderate readability with clear naming conventions and logical structure. However it suffers from a lengthy parameter list heavy reliance on external definitions textures symbols and constants without visible context. The binNumber calculation appears cryptic and indentation is inconsistent. While CUDA_SAFE_CALL macros aid error handling more inline documentation would help comprehension. Overall its accessible to experienced CUDA developers but challenging for newcomers.","tokens":2854,"name":"34.jsnp"}
{"score":"45","reasoning":"Code suffers from heavy macro dependency without context, complex shared memory sizing, and cryptic indexing arithmetic. The three-phase data loading (main, upper/lower halo) with subtle boundary conditions is hard to follow. Most critically, the kernel coefficient indexing appears erroneous and opaque: c_Kernel[(2*kernelRadius+1) + kernelRadius - j]. Optimized for performance over clarity, requiring deep CUDA convolution knowledge to comprehend.","tokens":2287,"name":"10.jsnp"}
{"score":"65","reasoning":"Code shows consistent CUDA error handling and logical structure but suffers from overly verbose variable names mixing conventions. Minimal comments lack context about the registration algorithm purpose. The dense grid calculation and pointer indirection add complexity. Debug output is helpful. Overall readable for CUDA experts but challenging for newcomers due to naming and missing documentation.","tokens":1888,"name":"25.jsnp"}
{"score":"72","reasoning":"Functions are short and simple with clear purpose but suffer from awkward naming conventions. GetNumberLayersSpaceNetwork and GetNumberNeuronsSpaceNetwork are not self-explanatory. Proper const usage and input validation via assert improve quality. spaceLayers[layer].neurons access is clear. Overall structure is good but naming hinders immediate comprehension.","tokens":1281,"name":"91.jsnp"}
{"score":"35","reasoning":"Missing context and comments. Cryptic variable names like I J dimIJ hinder understanding. Dense ternary operators and pointer arithmetic reduce clarity. CUDA kernel configurations are unclear. Inconsistent naming conventions. While the performance branching logic is sound the code demands deep domain knowledge. ContrastiveDivergence is overly compact. No error handling visible.","tokens":2580,"name":"33.jsnp"}
{"score":"65","reasoning":"Code snippet lacks context and contains uninitialized variable modeStr. Variable names like htod dtoh dtod wc are cryptic. Logical grouping exists but initialization style is inconsistent. Comment block is clear but heavy. Structure is acceptable for C but requires domain knowledge. These issues significantly reduce readability.","tokens":1762,"name":"74.jsnp"}
{"score":"65","reasoning":"CUDA kernel launch with verbose logging. Very long function name reduces readability. Dense printf with multiple parameters is hard to parse. Conditional compilation adds complexity. Lacks comments. Variable names G1/B1 are terse. Error checking is good. Understandable for CUDA developers but not beginner friendly. Structure is logical but could be cleaner.","tokens":1643,"name":"56.jsnp"}
{"score":"40","reasoning":"Code suffers from inconsistent spacing, unexplained magic numbers (128*128*50), and commented-out lines that clutter logic. Missing context about function purpose and variable meanings. While the core loop structure is simple, poor formatting and lack of comments significantly hinder readability and maintainability.","tokens":1316,"name":"2.jsnp"}
{"score":"35","reasoning":"Poor formatting with single-line functions and excessive comment blocks. Contains repetitive if-else chain with magic numbers and inconsistent shared memory calculations. Mathematical operations for power-of-two calculation are overly complex. Code lacks explanatory comments and uses abrupt section boundaries. Template kernel launches are hard to maintain and error-prone.","tokens":1875,"name":"78.jsnp"}
{"score":"65","reasoning":"The code shows clear binning logic for histogram calculation with proper boundary checks. However it suffers from repetitive A/B structures minimal commenting and questionable single-thread memory writes. Variable names follow CUDA conventions but remain cryptic. The incomplete snippet and confusing commented lines reduce clarity. Overall structure is functional but lacks modularity and detailed explanation of performance choices.","tokens":1796,"name":"27.jsnp"}
{"score":"55","reasoning":"Critical typo d_jont_hist causes confusion. Undefined BLOCK constant requires external knowledge. Double pointer pattern for device memory is non-standard and unclear. Commented CUDA_SAFE_CALL without explanation is puzzling. No error checking or documentation. While structurally correct for CUDA, these issues significantly hinder readability.","tokens":1483,"name":"118.jsnp"}
{"score":"25","reasoning":"Code features cryptic names like b0-b15 p0-p15 and single letters. Heavy macro usage with token pasting obscures control flow. Functions have 15+ parameters reducing readability. Backslashes for line continuation are nonstandard and distracting. Lacks comments and context. Highly specialized CUDA password cracking code prioritizes performance over clarity. Missing function definitions compound comprehension difficulty.","tokens":2578,"name":"114.jsnp"}
{"score":"35","reasoning":"Variable names like h_h, h_o, ppc are cryptic and lack context. Index arithmetic m*ppc/2 + i is ambiguous without parentheses. Integer division pitfalls and loop bound i \u003c\u003d ppc/2 are unclear. No comments explain purpose. Stray closing brace suggests incomplete context. While indentation is proper, overall comprehension requires significant effort and domain knowledge.","tokens":2100,"name":"80.jsnp"}
{"score":"25","reasoning":"This code exhibits severe readability issues: heavy macro abuse with token concatenation (##), excessively long variable names with redundant prefixes, repetitive patterns lacking proper abstraction, magic numbers in nested conditionals, and a function call with 15 parameters. The backslashes indicate macro context, compounding comprehension difficulty. While performance-critical GPU code may justify some complexity, the implementation is nearly incomprehensible without deep domain knowledge. No comments or documentation exist. The code appears generated rather than hand-written, prioritizing performance over maintainability to an extreme degree.","tokens":1838,"name":"69.jsnp"}
{"score":"48","reasoning":"Code suffers from poor naming conventions with abbreviations like transl and rotat, inconsistent function parameter naming, and unclear matrix layout. Lacks error handling for calloc failures. Uses magic number 12 without explanation. Depends on external undefined types and functions. Includes deprecated CUDA headers. Memory allocation on heap for small temporary matrices is inefficient. Cramped formatting reduces readability.","tokens":2026,"name":"94.jsnp"}
{"score":"30","reasoning":"Code uses cryptic abbreviated variable names like regH0 regE0 regT requiring deep domain knowledge to decipher. Comments are minimal vague and confusing especially compute the vector segment starting from 6. Logic is dense and low level typical of optimized CUDA kernels. While operations are simple and some comments exist overall readability is poor for general comprehension.","tokens":3918,"name":"97.jsnp"}
{"score":"40","reasoning":"Code uses cryptic variable names a b c d b0-b15 and macro-heavy structure MD5GG MD5HH with numerous magic hex constants. Long parameter lists reduce readability. Comments are minimal and informal. Requires deep MD5 algorithm knowledge to comprehend. While step numbers help, overall structure is dense and not self-documenting making it difficult for general developers to understand.","tokens":2268,"name":"53.jsnp"}
{"score":"35","reasoning":"Poor readability from C-style practices in C++ manual memory management raw pointers and C-style casts. Syntax errors include mismatched braces and undeclared loop variable. Incomplete comparison function missing equality case. Inconsistent indentation and minimal misleading comments. No error handling. Basic structure is followable but low quality implementation makes maintenance difficult.","tokens":2369,"name":"95.jsnp"}
{"score":"35","reasoning":"Severe naming confusion and inconsistency: first two functions swap block and grid dimensions B1 gets grid size G1 gets block size while third function is correct. This makes code extremely error-prone. Deprecated cudaThreadSynchronize repetitive debug code lack of comments and undefined Block constants further reduce readability. Critical conceptual flaw in CUDA parameter usage.","tokens":3112,"name":"110.jsnp"}
{"score":"68","reasoning":"CUDA kernel with standard parallel loop and clear index calculation. Very short variable names o w b hurt readability. No comments or context provided. Incomplete snippet prevents full comprehension. Logic is simple but requires domain knowledge.","tokens":1778,"name":"52.jsnp"}
{"score":"35","reasoning":"Code has severe repetition that should be a loop, cryptic variable names AS, BS, Csub, idnx, magic numbers 9-15, minimal comments, dense expressions like exp() calculation, inconsistent formatting, and lacks context. These issues make it very hard to understand or maintain without external knowledge.","tokens":2379,"name":"86.jsnp"}
{"score":"30","reasoning":"Code fragment is severely incomplete with missing struct opening braces and a closing brace for kernLaunchLL. The struct claims to be a linked list node but lacks a next pointer, making it misleading. Inconsistent indentation and partial commenting reduce readability. Variable names are somewhat descriptive but cannot compensate for structural flaws. Overall comprehension is poor due to fragmentation and missing essential elements.","tokens":1232,"name":"70.jsnp"}
{"score":"48","reasoning":"The code suffers from inconsistent formatting, cryptic variable names, and incomplete functions. Manual memory management is error-prone. Mixed C and C++ styles reduce clarity. Loop variable i is undeclared. The comparator function is truncated. While some comments exist, they are minimal. Overall structure is logical but execution lacks readability best practices.","tokens":1925,"name":"76.jsnp"}
{"score":"55","reasoning":"Code has readability issues: missing stdlib/stdio headers, inconsistent indentation, commented-out code without explanation, unexplained magic numbers (126), and lacks high-level comments. Variable names are clear but inconsistent declaration style (C89 vs C99) and redundant casts reduce clarity. Basic structure is logical but needs improvement for maintainability.","tokens":1530,"name":"4.jsnp"}
{"score":"35","reasoning":"Incomplete fragment lacks context. Bit manipulation is cryptic without comments. No variable declarations or function signatures shown. CUDA kernel declaration is truncated. Minimal variable names reduce clarity. While the bit operations follow a known pattern, overall comprehension requires significant domain knowledge and inference due to missing surrounding code and documentation.","tokens":1712,"name":"29.jsnp"}
{"score":"72","reasoning":"CUDA parallel reduction for finding minimum values and positions. Uses manually unrolled loops for block sizes 512 down to 16 with clear repetitive pattern. Lacks comments explaining algorithm and purpose of volatile pointers in final warp. Variable names are descriptive and indentation consistent. Familiar pattern for CUDA developers but cryptic for others. Repetitive structure aids comprehension but creates maintenance burden.","tokens":2928,"name":"59.jsnp"}
{"score":"48","reasoning":"CUDA NMF code with minimal documentation. Clear matrix dimension variables but cryptic kernel names (UpdateH_MD, UpdateW_MD) and unexplained helper functions. Relies on undeclared class members (gh,bh,gw,bw). Mathematical operations are implicit. Readable for CUDA/NMF experts but difficult for general developers. Section comments help but are insufficient.","tokens":1762,"name":"75.jsnp"}
{"score":"65","reasoning":"Code shows moderate readability. It has descriptive comments and meaningful variable names. However inconsistent naming conventions sw versus p prefixes confuse API layers, there is a typo in comment subsitution, fragmented context, no error handling for CUDA calls, dense formatting, and verbose macro names. Experienced CUDA developers can follow operations but abstraction inconsistencies hinder maintenance and debugging.","tokens":2884,"name":"49.jsnp"}
{"score":"45","reasoning":"Code shows inconsistent formatting with tab-aligned parameters and abrupt termination. Lacks documentation comments despite decorative header. Uses cryptic double pointer float4 array_d and constant symbols c_ImageSize without explanation. Function name is descriptive but assumes deep CUDA and NIfTI knowledge. Incomplete body prevents full comprehension. Mixed naming conventions reduce clarity. Overall structure hints at purpose but poor formatting and missing context significantly hinder readability.","tokens":1415,"name":"1.jsnp"}
{"score":"30","reasoning":"Thirty repetitive macro calls with incremental values. No comments explain purpose or why range 19-48 is used. Clear pattern but opaque semantics. Violates DRY principle creating maintenance issues. Requires macro definition for comprehension. Represents poor manual code generation practice.","tokens":1885,"name":"83.jsnp"}
{"score":"58","reasoning":"Code has inconsistent indentation and formatting. Matrix multiplication is repeated three times instead of using a loop. Long expressions have poor alignment. Mixed use of sourceImageSize and c_SourceDim. Final closing brace appears extraneous. Comments are minimal. Logic is understandable but requires effort to follow due to structural issues.","tokens":2146,"name":"71.jsnp"}
{"score":"35","reasoning":"Missing context and macro definitions hinder comprehension. Variables use cryptic single letter names. Magic number 16 lacks explanation. Inconsistent indentation obscures structure. The dual assignment pattern with x increment is unclear. No comments explain synchronization or memory access strategy. While terse syntax is common in CUDA this code sacrifices too much readability for brevity.","tokens":1794,"name":"66.jsnp"}
{"score":"60","reasoning":"Inconsistent indentation and undefined BLOCK constant reduce clarity. Commented out code creates clutter. No documentation explains purpose or parameters. Unclear grid calculation uses third dimension for y axis. While CUDA_SAFE_CALL is used correctly, reliance on external symbols and convoluted float array to struct conversions make maintenance difficult.","tokens":2996,"name":"79.jsnp"}
{"score":"25","reasoning":"Code snippet shows poor readability practices: includes deprecated CUDA headers (cutil_inline.h, cutil_math.h), uses non-standard leading underscore in header name, mixes inclusion styles without clear logic, and defines a magic number macro without comments or context. Lack of documentation and inconsistent conventions make comprehension difficult despite brevity.","tokens":1149,"name":"40.jsnp"}
{"score":"30","reasoning":"Code uses cryptic variable names a-e b0-b15 redundant indexing like 0*CONSTANT and unclear macros CREATE_SHA1_CH_KERNEL. Heavy reliance on globals magic numbers and lacks comments. Backslashes indicate missing macro context. While functional for CUDA SHA1 kernels it is unnecessarily dense. Descriptive names constants for offsets and documentation would greatly improve readability.","tokens":2255,"name":"84.jsnp"}
{"score":"30","reasoning":"Extremely cryptic variable naming vd vr hd hr dat rec e with no context. Incomplete snippet missing braces. Only one vague comment. CUDA thread indexing syncthreads and shared memory usage unexplained. Complex array indexing requires domain knowledge. Algorithm intent is opaque. Compactness is only positive but hinders comprehension.","tokens":2175,"name":"44.jsnp"}
{"score":"35","reasoning":"Heavy macro token pasting obscures function generation. Cryptic variable names b0-b15 and a-e mixed with inconsistent SHA1MD5 naming create confusion. Dense bit operations lack comments. Long parameter lists and undefined external macros demand deep context. Performance-focused structure is logical but severely hinders readability for outsiders.","tokens":2576,"name":"38.jsnp"}
{"score":"30","reasoning":"Code snippet is incomplete with missing declarations for idnx idny sum and output_width. Poor variable naming using single letters a b and cryptic abbreviations idnx idny. Inconsistent naming conventions between PascalCase and snake_case. Misspelled EuclidianDistance. Hardcoded blockSize without explanation. Mismatched braces and abrupt ending with incomplete FindMinKernel declaration. No comments explaining purpose. Lacks CUDA error checking. However the core Euclidean distance logic is recognizable.","tokens":1653,"name":"15.jsnp"}
{"score":"55","reasoning":"Macro definitions with readability issues. Commented include is confusing. THRESHOLD lacks context. MAX macro missing parentheses risks bugs. Vague section comment. Minimal documentation. Simple structure is only positive.","tokens":1478,"name":"109.jsnp"}
{"score":"35","reasoning":"Macro name excessively long and cryptic reducing readability. Repetitive calls lack context and comments. Numeric pattern is clear but purpose remains obscure without domain knowledge. Simple structure is overshadowed by poor naming conventions.","tokens":1485,"name":"45.jsnp"}
{"score":"20","reasoning":"Code exhibits extremely poor readability due to cryptic variable names b0-b15 p0-p15 macro usage with token pasting deep nesting and lack of comments. CUDA kernel structure is obscured by generated-code patterns and excessive parameters. While the host function is clearer overall comprehension requires deep cryptographic and CUDA domain knowledge. Performance optimizations severely harm maintainability.","tokens":2011,"name":"108.jsnp"}
{"score":"40","reasoning":"Poor variable naming (W,V,H,aux) and cryptic operations hinder readability. In-place transposition of W called twice creates confusing state changes. Commented-out code clutters the snippet. No explanatory comments beyond generic Update H label. deltaH vs deltaH2 distinction unclear. While structurally coherent, the code requires deep domain knowledge to understand algorithmic intent.","tokens":2411,"name":"32.jsnp"}
{"score":"62","reasoning":"The code snippet shows CUDA memory allocation and dimension setup for neural network operations. Variable names follow some conventions like d prefix for device memory but lack clarity on purpose. No comments explain the context or the meaning of Fire or why neurons plus 1 is used. Requires deep domain knowledge of CUDA and neural networks to understand. The structure is simple and linear but the intent remains opaque without additional context.","tokens":1640,"name":"8.jsnp"}
{"score":"78","reasoning":"Clear function names and consistent error handling pattern make this network code readable. Good use of perror and logging aids debugging. Minor issues include magic numbers (listen backlog\u003d1, buffer size 128), unusual alignment spacing in declarations, and incomplete final function. Comments are helpful but sparse. Overall structure is solid and follows C networking conventions well.","tokens":1792,"name":"17.jsnp"}
{"score":"48","reasoning":"Snippet starts mid-block lacking context. Cryptic variable names (vd, hd, vr, hr, u, d) reduce clarity. Complex thread-dependent logic requires CUDA expertise. Multi-parameter function calls are hard to track. Sparse comments help but insufficient. Structure is logical for parallel neural network updates but readability suffers from inconsistent naming and missing context.","tokens":2591,"name":"48.jsnp"}
{"score":"68","reasoning":"CUDA kernel launch code with standard block/grid setup. Contains typo d_jont_hist reducing clarity. Uses deprecated cudaThreadSynchronize(). Grid calculation is correct but dense. Parameter list is long without line breaks. Unusual pointer dereferencing syntax. Good device pointer naming convention but lacks comments. Understandable for experienced CUDA developers but has several readability issues and potential bugs.","tokens":1428,"name":"63.jsnp"}
{"score":"35","reasoning":"Code suffers from severe formatting inconsistencies, poor indentation, and mixed brace styles. Variable names are often cryptic (fp, ioc) and lack clarity. Minimal comments and documentation make understanding intent difficult. Potential bugs in malloc error checking and unnecessary void casts reduce confidence. The incomplete snippet context further hampers comprehension. Overall structure is disorganized with static declarations interspersed randomly.","tokens":2024,"name":"37.jsnp"}
{"score":"40","reasoning":"The code suffers from cryptic naming conventions (single-letter variables, inconsistent kernel names), excessively long parameter lists, and heavy reliance on undocumented macros and member variables. Conditional compilation adds complexity. Pointer arithmetic and dense mathematical expressions reduce clarity. Lack of comments makes understanding context-dependent. While functional, it requires significant domain knowledge and class definition to comprehend. The incomplete function ending further reduces readability.","tokens":3093,"name":"30.jsnp"}
{"score":"35","reasoning":"Fragmented C code with commented-out conditional logic creating unclear execution flow. Inconsistent indentation severely hampers readability. TODO block with commented cleanup code suggests improper resource management fix. Lack of context for variables and functions prevents full comprehension. Poor maintenance practice with dead code left in place.","tokens":1467,"name":"54.jsnp"}
{"score":"70","reasoning":"Code fragment lacks context for full comprehension. The self-equality NaN check is correct but cryptic without explanatory comments. Variable names are highly descriptive and properly initialized. Structure is logical but the unexplained idiom and missing surrounding code reduce readability.","tokens":2805,"name":"77.jsnp"}
{"score":"55","reasoning":"The code has repetitive X Y Z blocks that should be refactored. Variable names are mixed, some clear like jointEntropyDerivative_X but others vague like temp and c_Entropies.z. Reusing temp is confusing. Comments like // t give no context. The final gradient calculation is clear and shows the formula well. Overall structure is logical but the redundancy and cryptic parts hurt readability.","tokens":2972,"name":"117.jsnp"}
{"score":"40","reasoning":"Code suffers from inconsistent formatting with mismatched brace styles and unnecessary blank lines. Repeated casting of void pointer to uint8_t clutters loops reducing clarity. Magic number 255 lacks context. No comments explain intent. Inconsistent loop brace usage creates visual noise. While logic is simple these issues significantly hinder quick comprehension and maintainability.","tokens":3531,"name":"22.jsnp"}
